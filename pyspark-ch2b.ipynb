{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To run Kafka**\\\n",
    "bin/zookeeper-server-start.sh config/zookeeper.properties\\\n",
    "bin/kafka-server-start.sh config/server.properties\n",
    "\n",
    "**producer and consumer**\\\n",
    "bin/kafka-console-consumer.sh --topic retail-events --from-beginning --bootstrap-server localhost:9092\\\n",
    "bin/kafka-console-producer.sh --topic retail-events --bootstrap-server localhost:9092\n",
    "\n",
    "**pyspark with kafka support**\\\n",
    "pyspark --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/23 15:31:24 WARN Utils: Your hostname, CarlPC resolves to a loopback address: 127.0.1.1; using 172.25.228.240 instead (on interface eth0)\n",
      "22/05/23 15:31:24 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/nolfonzo/spark-3.2.1-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/nolfonzo/spark-3.2.1-bin-hadoop3.2/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/nolfonzo/.ivy2/cache\n",
      "The jars for the packages stored in: /home/nolfonzo/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-1a1c4fe4-0e7f-4514-b22d-0f2db2792ba8;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.2.1 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.2.1 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.8.0 in central\n",
      "\tfound org.lz4#lz4-java;1.7.1 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.4 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.1 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.1 in central\n",
      "\tfound org.apache.htrace#htrace-core4;4.1.0-incubating in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.6.2 in central\n",
      ":: resolution report :: resolve 1061ms :: artifacts dl 26ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.6.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.1 from central in [default]\n",
      "\torg.apache.htrace#htrace-core4;4.1.0-incubating from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.8.0 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.2.1 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.2.1 from central in [default]\n",
      "\torg.lz4#lz4-java;1.7.1 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.4 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   13  |   0   |   0   |   0   ||   13  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-1a1c4fe4-0e7f-4514-b22d-0f2db2792ba8\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 13 already retrieved (0kB/19ms)\n",
      "22/05/23 15:31:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "#\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.1 pyspark-shell'\n",
    "import pyspark;\n",
    "sc = pyspark.SparkContext.getOrCreate();\n",
    "from pyspark.sql import SparkSession;\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Ingestion\n",
    "# loaded the CSV files with the header and inferSchema options enabled. \n",
    "# This creates a Spark DataFrame with eight columns along with their respective data types and column names\n",
    "retail_df = (spark \\\n",
    "   .read \\\n",
    "   .option(\"header\", \"true\") \\\n",
    "   .option(\"inferSchema\", \"true\") \\\n",
    "   .csv(\"/home/nolfonzo/src/pyspark/Essential-PySpark-for-Scalable-Data-Analytics/data/online_retail/online_retail_small.csv\") \\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|   InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|01/12/10 08:26|     2.55|     17850|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|01/12/10 08:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|01/12/10 08:26|     2.75|     17850|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|01/12/10 08:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|01/12/10 08:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|01/12/10 08:26|     7.65|     17850|United Kingdom|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|01/12/10 08:26|     4.25|     17850|United Kingdom|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|01/12/10 08:28|     1.85|     17850|United Kingdom|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|01/12/10 08:28|     1.85|     17850|United Kingdom|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retail_df.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Structured Parquet file format is the optimal format to be used to store data in data lakes with Apache Spark\n",
    "# Other structured formats: relational databases, Avro, OCR files\n",
    "#\n",
    "# save the retail_df Spark DataFrame, containing raw retail transactions, to the data lake in Parquet format\n",
    "(retail_df \\\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(\"/tmp/data-lake/online_retail_small.parquet\") \\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|   InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|   489434|    85048|15CM CHRISTMAS GL...|      12|01/12/09 07:45|     6.95|     13085|United Kingdom|\n",
      "|   489434|   79323P|  PINK CHERRY LIGHTS|      12|01/12/09 07:45|     6.75|     13085|United Kingdom|\n",
      "|   489434|   79323W| WHITE CHERRY LIGHTS|      12|01/12/09 07:45|     6.75|     13085|United Kingdom|\n",
      "|   489434|    22041|\"RECORD FRAME 7\"\"...|      48|01/12/09 07:45|      2.1|     13085|United Kingdom|\n",
      "|   489434|    21232|STRAWBERRY CERAMI...|      24|01/12/09 07:45|     1.25|     13085|United Kingdom|\n",
      "|   489434|    22064|PINK DOUGHNUT TRI...|      24|01/12/09 07:45|     1.65|     13085|United Kingdom|\n",
      "|   489434|    21871| SAVE THE PLANET MUG|      24|01/12/09 07:45|     1.25|     13085|United Kingdom|\n",
      "|   489434|    21523|FANCY FONT HOME S...|      10|01/12/09 07:45|     5.95|     13085|United Kingdom|\n",
      "|   489435|    22350|           CAT BOWL |      12|01/12/09 07:46|     2.55|     13085|United Kingdom|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(key='0', value='{\"InvoiceNo\":536365,\"StockCode\":\"85123A\",\"Description\":\"WHITE HANGING HEART T-LIGHT HOLDER\",\"Quantity\":6,\"InvoiceDate\":\"01/12/10 08:26\",\"UnitPrice\":2.55,\"CustomerID\":17850,\"Country\":\"United Kingdom\"}'),\n",
       " Row(key='1', value='{\"InvoiceNo\":536365,\"StockCode\":\"71053\",\"Description\":\"WHITE METAL LANTERN\",\"Quantity\":6,\"InvoiceDate\":\"01/12/10 08:26\",\"UnitPrice\":3.39,\"CustomerID\":17850,\"Country\":\"United Kingdom\"}'),\n",
       " Row(key='2', value='{\"InvoiceNo\":536365,\"StockCode\":\"84406B\",\"Description\":\"CREAM CUPID HEARTS COAT HANGER\",\"Quantity\":8,\"InvoiceDate\":\"01/12/10 08:26\",\"UnitPrice\":2.75,\"CustomerID\":17850,\"Country\":\"United Kingdom\"}'),\n",
       " Row(key='3', value='{\"InvoiceNo\":536365,\"StockCode\":\"84029G\",\"Description\":\"KNITTED UNION FLAG HOT WATER BOTTLE\",\"Quantity\":6,\"InvoiceDate\":\"01/12/10 08:26\",\"UnitPrice\":3.39,\"CustomerID\":17850,\"Country\":\"United Kingdom\"}'),\n",
       " Row(key='4', value='{\"InvoiceNo\":536365,\"StockCode\":\"84029E\",\"Description\":\"RED WOOLLY HOTTIE WHITE HEART.\",\"Quantity\":6,\"InvoiceDate\":\"01/12/10 08:26\",\"UnitPrice\":3.39,\"CustomerID\":17850,\"Country\":\"United Kingdom\"}'),\n",
       " Row(key='5', value='{\"InvoiceNo\":536365,\"StockCode\":\"22752\",\"Description\":\"SET 7 BABUSHKA NESTING BOXES\",\"Quantity\":2,\"InvoiceDate\":\"01/12/10 08:26\",\"UnitPrice\":7.65,\"CustomerID\":17850,\"Country\":\"United Kingdom\"}'),\n",
       " Row(key='6', value='{\"InvoiceNo\":536365,\"StockCode\":\"21730\",\"Description\":\"GLASS STAR FROSTED T-LIGHT HOLDER\",\"Quantity\":6,\"InvoiceDate\":\"01/12/10 08:26\",\"UnitPrice\":4.25,\"CustomerID\":17850,\"Country\":\"United Kingdom\"}'),\n",
       " Row(key='7', value='{\"InvoiceNo\":536366,\"StockCode\":\"22633\",\"Description\":\"HAND WARMER UNION JACK\",\"Quantity\":6,\"InvoiceDate\":\"01/12/10 08:28\",\"UnitPrice\":1.85,\"CustomerID\":17850,\"Country\":\"United Kingdom\"}'),\n",
       " Row(key='8', value='{\"InvoiceNo\":536366,\"StockCode\":\"22632\",\"Description\":\"HAND WARMER RED POLKA DOT\",\"Quantity\":6,\"InvoiceDate\":\"01/12/10 08:28\",\"UnitPrice\":1.85,\"CustomerID\":17850,\"Country\":\"United Kingdom\"}')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|key|               value|\n",
      "+---+--------------------+\n",
      "|  0|{\"InvoiceNo\":5363...|\n",
      "|  1|{\"InvoiceNo\":5363...|\n",
      "|  2|{\"InvoiceNo\":5363...|\n",
      "|  3|{\"InvoiceNo\":5363...|\n",
      "|  4|{\"InvoiceNo\":5363...|\n",
      "|  5|{\"InvoiceNo\":5363...|\n",
      "|  6|{\"InvoiceNo\":5363...|\n",
      "|  7|{\"InvoiceNo\":5363...|\n",
      "|  8|{\"InvoiceNo\":5363...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Structured Streaming has built-in mechanisms to help you to easily maintain the state information that is required for an incremental load\n",
    "# \n",
    "# Following code creates a DF for kafka broadcasting, columns converted to a JSON string\n",
    "# \n",
    "from pyspark.sql.functions import to_json, struct, from_json, monotonically_increasing_id\n",
    "#\n",
    "kafka_broadcast_df = retail_df.withColumn(\"key\", monotonically_increasing_id().cast(\"STRING\")).withColumn(\"value\", to_json(struct([retail_df[x] for x in retail_df.columns])).cast(\"STRING\"))\n",
    "kafka_broadcast_df.select(\"key\", \"value\").collect()\n",
    "kafka_broadcast_df.select(\"key\", \"value\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcast kafka_df to retail-events topic\n",
    "kafka_broadcast_df.select(\"key\", \"value\")\\\n",
    "  .write\\\n",
    "  .format(\"kafka\")\\\n",
    "  .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\\\n",
    "  .option(\"topic\", \"retail-events\")\\\n",
    "  .save()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2678a815613a486355418d7a646a043051186984e97816ceb1e10bd784649dbc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
